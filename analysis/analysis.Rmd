---
title: "R Notebook"
output:
  html_document:
    df_print: paged
    toc: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)

library(tidyverse)
library(pbapply)
library(ggplot2)
library(janitor)
library(stringr)
library(anytime)
library(DT)

# this is where the result of the parallel is stored
RUN_DIR=file.path("..", "runs/packages")
```

```{r aux funs}
package_stat <- function(path) {
  data.frame(
    on.exit_set_log=file.exists(file.path(path, "trace-on.exit--set", "parallel.log")),
    on.exit_set=file.exists(file.path(path, "trace-on.exit--set", "output", "all", "genthat-tracing.csv")),
    on.exit_seq=file.exists(file.path(path, "trace-on.exit--sequence", "output", "all", "genthat-tracing.csv")),
    onexit_set=file.exists(file.path(path, "trace-onexit--set", "output", "all", "genthat-tracing.csv")),
    onexit_seq=file.exists(file.path(path, "trace-onexit--sequence", "output", "all", "genthat-tracing.csv")),
    count_entry_seq=file.exists(file.path(path, "trace-count-entry--sequence", "output", "all", "genthat-tracing.csv")),
    count_exit_seq=file.exists(file.path(path, "trace-count-exit--sequence", "output", "all", "genthat-tracing.csv")),
    run_log=file.exists(file.path(path, "run", "parallel.log")),
    run=file.exists(file.path(path, "run", "output", "all", "genthat-runs.csv")),
    run_package=file.exists(file.path(path, "run-package", "output", "all", "genthat-tracing.csv")),
    coverage=file.exists(file.path(path, "coverage", "output", "all", "covr.RDS"))
  )
}

format_difftime <- function(x, ...) {
  if (is.na(x)) return(NA)

  x <- as.integer(x)
  sprintf(
    "%02d:%02d:%02d", 
    x %% (24*60*60) %/% (60*60),
    x %% (60*60) %/% 60,
    x %% 60 %/% 1
  )
}

format_size <- function(x) {
  if (is.na(x)) return(NA)
  
  units <- c("B", "kB", "MB", "GB", "TB", "PB")
  
  fmt <- function(x, i=1) {
    xx <- x / 1024
    if (abs(xx) > 1 && i < length(units)) {
      fmt(xx, i+1)
    } else {
      sprintf("%.2f %s", x, units[i])
    }
  }
  
  sapply(x, fmt, USE.NAMES=FALSE)
}

load_file_from_packages <- function(filepath, from, fun) {
  transmute(from, package, fname=file.path(path, filepath)) %>% 
    pmap_dfr(fun)
}

read_csv_checked <- function(...) {
  tryCatch(read_csv(...), error=function(e) {
    message(..1, ": error: ", e$message)
  }, warning=function(e) {
    message(..1, ": warning: ", e$message)
  })
}

load_csvs <- function(path, from, ...) {
  load_file_from_packages(path, from, function(package, fname) {
    df <- read_csv_checked(fname, ...)
    mutate(df, package=package) %>% select(package, everything())
  })
}

load_traces <- function(config) {
  load_csvs(file.path(str_c("trace-", config), "output", "all", "genthat-tracing.csv"), from=packages, 
    col_types=cols_only(
      file="c",
      output="c",
      error="c"
    )
  )
}
```

```{r parallel logs aux}
read_parallel_log <- function(package, fname) {
  read_tsv(
    fname, 
    col_types=cols_only(
      Seq="i",
      Starttime="d",
      JobRuntime="d",
      Exitval="i",
      Signal="i",
      Command="c"
    )
  ) %>%
  transmute(
    package=package,
    started=anytime(Starttime),
    ended=anytime(Starttime+JobRuntime),
    duration=ended-started,
    status=Exitval,
    signal=Signal,
    command=Command
  )
}

read_parallel_logs <- function(task_name, from) {
  load_file_from_packages(file.path(task_name, "parallel.log"), from=from, fun=read_parallel_log)
}

load_trace_log <- function(config, from) {
  read_parallel_logs(str_c("trace-", config), from=from) %>%
    mutate(
      config=str_replace(command, ".* --config ([^ ]+) .*", "\\1"),
      decorator=str_replace(config, "(.*)--(.*)", "\\1"),
      tracer=str_replace(config, "(.*)--(.*)", "\\2")
    ) %>%
    select(-config)
}
```

# Load data

```{r find packages}
all_packages <- 
  data_frame(path=list.dirs(RUN_DIR, recursive=FALSE)) %>%
  filter(!endsWith(path, "/1")) %>%
  mutate(package=basename(path))

all_packages <-
  bind_cols(all_packages, package_stat(all_packages$path))

all_packages_obs <-
  all_packages %>%
  gather(
    key="task", 
    value="success", 
    count_entry_seq, on.exit_set, run, run_package, coverage
  )

# the subset of packages that made it till the end
packages <- filter(
  all_packages, 
  on.exit_set==TRUE, 
#  on.exit_seq==TRUE, 
#  onexit_seq==TRUE, 
#  count_entry_seq==TRUE, 
  run==TRUE
)
```

```{r load data}
on_entry_seq <- load_traces("count-entry--sequence")
on_exit_seq <- load_traces("on.exit--sequence")

traces <- load_traces("on.exit--set")
runs <- load_csvs(file.path("run", "output", "all", "genthat-runs.csv"), from=packages, col_types=cols_only(
    file="c",
    test="c",
    nb="i",
    failed="i",
    error="l",
    warning="i",
    run_error="c",
    elapsed="d",
    output="c"
  )
)

trace_log <- load_trace_log("on.exit--set", from=filter(all_packages, on.exit_set_log))
run_log <- read_parallel_logs("run", filter(all_packages, run_log))
```

```{r process data}
sum_traces <- function(traces) {
  df <- 
    group_by(traces, package) %>% 
    summarise(traces=n(), tests=sum(is.na(error)), failures=sum(!is.na(error)))
  
  # a sanity check (the verbose code is for debugging the bad ones)
  stopifnot(
    mutate(df, d = traces - tests - failures) %>% 
      filter(d != 0) %>% 
      nrow() == 0
  )
  
  df
}

s_traces <- 
  sum_traces(traces) %>%
  filter(traces > 0) %>%
  mutate(tests_traces=tests / traces)

p_runs <-
  filter(runs, is.na(nb) | (nb - warning) <= 1) %>%
  transmute(
    package,
    fun=test,
    failed=ifelse(is.na(failed), FALSE, failed == 1),
    error=ifelse(is.na(error), FALSE, error),
    exception=ifelse(is.na(nb), TRUE, FALSE),
    passed=(failed + error + exception == 0),
    elapsed=ifelse(is.na(elapsed), 0, elapsed),
    file
  )

s_runs <-
  group_by(p_runs, package) %>%
  summarise(failed=sum(failed), error=sum(error), exception=sum(exception), passed=sum(passed))
```

## Summary

### Absolute

```{r}
n_traces <- sum(s_traces$traces)
n_tests <- sum(s_traces$tests)
n_runs <- sum(s_runs$passed)
```

Overall we have `r n_traces` traces out of which we generate `r n_tests` tests which is `r n_tests/n_traces*100`%.
We can run `r n_runs` tests which is `r n_runs/n_tests*100`% of tests and `r n_runs/n_traces*100` % of all traces.

### Relative

We tried to run `r nrow(all_packages)`. 
From that `r nrow(packages)` finished. 
From that `r nrow(s_traces)` had some traces and `r nrow(s_runs)` had some tests.

```{r}
summary_stats <-
  filter(s_traces, traces > 0) %>%
  left_join(s_runs, by="package") %>%
  mutate_all(funs(replace(., is.na(.), 0))) %>%
  transmute(package, passed_traces=passed / traces, passed_tests=ifelse(tests > 0, passed / tests, 0))
```

- Ratio of calls we can reprodue out of all captured calls

```{r}
summary(summary_stats$passed_traces)
```

- Ratio of calls we can reproduce out of the calls we can generate tests for

```{r}
summary(summary_stats$passed_tests)
```

## Participating packages

### Selected packages

```{r package list}
select(all_packages, package, path) %>% datatable()
```

### Failed packages

```{r}
all_packages_obs %>%
  filter(!success) %>%
  count(task) %>%
  datatable()
```

```{r fig.height=40}
all_packages_obs %>%
  filter(!(task %in% c("onexit_set", "count_exit_seq", "coverage", "run_package")), success==FALSE) %>%
  ggplot(aes(
    x=factor(
      task, 
      levels=c(
        "count_entry_seq", 
        "count_exit_seq", 
        "on.exit_set", 
        "on.exit_seq", 
        "onexit_set", 
        "onexit_seq", 
        "run", 
        "run_package", 
        "coverage"
      )
    ), 
    y=package)
  ) + 
  geom_point() + 
  theme(strip.text.y=element_text(angle = 0)) +
  labs(
    title="Running failures",
    subtitle="Which packages failed on which tasks",
    x="Task",
    y="Package"
  )
```

- Failed tracing and generating

```{r}
select(trace_log, package, duration, status, signal) %>% filter(status != 0) %>% datatable()
```

- Failed running

```{r}
select(run_log, package, duration, status, signal) %>% filter(status != 0) %>% datatable()
```

# Results

## Errors

The following stats are for all the tests across all the packages.

### Error messages during tracing

```{r gen errors}
traces %>%
  mutate(error=ifelse(is.na(error), "No error", error)) %>%
  count(error) %>%
  arrange(desc(n)) %>%
  datatable()
```

### Categories of error messages during tracing

```{r}
traces %>%
  mutate(
    error=ifelse(is.na(error), "No error", error),
    error=ifelse(startsWith(error, "Generate error: Trace error:"), "Trace error", error),
    error=ifelse(startsWith(error, "Generate error"), "Generate error", error)
  ) %>%
  count(error) %>%
  arrange(desc(n)) %>%
  datatable()
```

### How much any of these contributes to tracing failures for individual packages

```{r}
n_success_traces <- nrow(filter(traces, is.na(error)))

traces %>%
  filter(!is.na(error)) %>%
  count(error) %>%
  filter(n > n_success_traces*0.001) %>%
  select(-n) %>%
  left_join(traces, by="error") %>%
  count(package, error) %>%
  left_join(s_traces, by="package") %>%
  mutate(r=n/traces, d=failures-n) %>%
  filter(r > .1) %>%
  arrange(desc(r)) %>%
  datatable()
```

#### Details for debugging

```{r}
generr_ratio <- function(pattern) {
  err <- traces %>% filter(grepl(pattern, error)) %>% count(package)
  s_traces %>% 
    right_join(err, by="package") %>% 
    mutate(r=n/traces, d=failures) %>% 
    arrange(desc(r))
}
```

- `Generate error: Serialization error: SEXP type S4SXP not supported!`

```{r}
generr_ratio("S4SXP") %>% filter(r > 0.1) %>% datatable()
```

- `Generate error: Serialization error: Serialized data structure contains cycle!`

```{r}
generr_ratio("Serialized data structure contains cycle") %>% filter(r > 0.1) %>% datatable()
```

- `Generate error: Serialization error: SEXP type PROMSXP not supported!`

```{r}
generr_ratio("PROMSXP") %>% filter(r > 0.1) %>% datatable()
```

- `Generate error: Serialization error: SEXP type EXTPTRSXP not supported!`

```{r}
generr_ratio("EXTPTRSXP") %>% filter(r > 0.1) %>% datatable()
```

- `Generate error: STRING_ELT() can only be applied to a 'character vector', not a 'NULL'`

```{r}
generr_ratio("STRING_ELT\\(\\) can only be applied to") %>% filter(r > 0.1) %>% datatable()
```

## Running

### Inconsitent data

Likely packages using testthat themselves

```{r}
runs %>% filter((nb - warning) > 1) %>% count(package) %>% datatable()
```

```{r run errors}
runs %>%
  transmute(run_error=ifelse(is.na(run_error), "No run_error", run_error)) %>%
  count(run_error) %>%
  arrange(desc(n)) %>%
  datatable()
```

### Test numbers

- Check inconsitencies

```{r}
p_runs %>% rowwise() %>% mutate(x=sum(passed, failed, error, exception)) %>% filter(x>1)
```

#### Errors

```{r run tests results, fig.height=13}
s_runs %>%
  mutate(
    n=failed+error+exception+passed,
    passed=ifelse(n > 0, passed/n, 0),
    failed=ifelse(n > 0, failed/n, 0),
    error=ifelse(n > 0, error/n, 0),
    exception=ifelse(n > 0, exception/n, 0)
  ) %>%
  filter(passed < 1) %>%
  gather(key="key", value="value", passed, failed, error, exception) %>%
  ggplot(aes(x=package, y=value, fill=key)) +
  geom_col() +
  coord_flip() +
  scale_fill_manual(values=c("error"="orange", "exception"="black", "failed"="red", "passed"="green")) +
  labs(
    title="Test running results",
    x="Package",
    y="Ratio of different results"
  )
```

## Summary

```{r success rate}
success_rate <- select(s_traces, package, n_traces, n_success) %>%
  left_join(select(s_runs, package, passed), by="package") %>%
  mutate(
    generated_traced=ifelse(n_traces > 0, n_success/n_traces, 0),
    passed_generated=ifelse(n_traces > 0, passed/n_success, 0),
    passed_traced=ifelse(n_success > 0, passed/n_traces, 0)
  )
```

```{r success rate overview}
success_rate %>%
  gather(key="key", value="value", generated_traced, passed_generated, passed_traced) %>%
  ggplot(aes(x=key, y=value)) +
  geom_boxplot() +
  scale_y_continuous(labels=scales::percent_format()) +
  labs(
    title="Overall success rate",
    subtitle="How many calls we reproduce?",
    x="Metric",
    y="Success rate"
  )
```

#### Success rate in numbers

```{r}
stats <- fBasics::basicStats(success_rate %>% select(generated_traced, passed_generated, passed_traced)) %>% as_data_frame()

bind_cols(data_frame(stats=rownames(stats)), stats)
```

### Missed traces

```{r load other trace stats}
n_count_entry_seq_traces <- sum_traces(on_entry_seq)
#n_count_exit_seq_traces <- sum_traces(count_exit_seq_traces)
n_onexit_seq_traces <- sum_traces(onexit_seq_traces)
n_ondotexit_seq_traces <- sum_traces(ondotexit_seq_traces)
```

### Missing calls and traces

The following tries to estimate the number of missing calls. A missing call is a call that either did not terminate normally (there was an exception or a long jump) or did exit normally, but there was an exception (or something) that prevented the recorder to store the complete trace.
The former one is referred to as _missed call_ and the latter as _missed trace_.
The way we masure them is by running code with decorators that only records calls entries and exits without looking at any arguments.


```{r missing calls plot, fig.height=13}
missing_calls <-
  inner_join(
    select(count_entry_seq_traces, package, type, tag, n_entry=n_traces),
    select(ondotexit_seq_traces, package, type, tag, n_traces, n_complete),
    by=c("package", "type", "tag")
  ) %>%
  select(package, type, tag, n_entry, n_traces, n_complete)

n_missing_calls <- missing_calls %>%
  group_by(package) %>%
  summarise(
    n_entry=sum(n_entry),
    n_traces=sum(n_traces),
    n_complete=sum(n_complete)
  ) %>%
  mutate(
    calls=ifelse(n_entry > 0, 1-n_traces/n_entry, 0),
    traces=ifelse(n_traces > 0, 1-n_complete/n_traces, 0),
    total=calls+traces
  ) %>%
  select(package, calls, traces, total)

n_missing_calls  %>%
  gather(key="key", value="value", calls, traces) %>%
  filter(value != 0) %>%
  ggplot(
    aes(
      x=factor(package, levels=n_missing_calls$package[order(n_missing_calls$total)]), 
      y=value, 
      fill=key
    )
  ) +
  geom_col(position="dodge") +
  scale_y_continuous(labels=scales::percent_format()) +
  scale_fill_discrete(labels=c("calls"="Missed calls", "traces"="Missed traces")) +
  coord_flip() +
  labs(
    title="Missing calls/traces",
    subtitle="How many calls/traces did we missed?",
    x="Package (for which ration != 0)",
    y="Ratio of missing calls/traces",
    fill="Ratio"
  )
```

The following shows how many calls we miss because there is an exception during the arguments recording.

```{r}
n_missing_calls  %>%
  filter(traces != 0) %>%
  ggplot(
    aes(
      x=factor(package, levels=n_missing_calls$package[order(n_missing_calls$traces)]), 
      y=traces
    )
  ) +
  geom_col() +
  scale_y_continuous(labels=scales::percent_format()) +
  scale_fill_discrete(labels=c("calls"="Missed calls", "traces"="Missed traces")) +
  coord_flip() +
  labs(
    title="Missing traces",
    subtitle="How many traces did we missed?",
    x="Package (for which ration != 0)",
    y="Ratio of missing traces",
    fill="Ratio"
  )
```

## on.exit vs onexit

```{r fig.height=15}
diffs_calls <-
  full_join(
    select(count_entry_seq_traces, package, type, tag, n_entry), 
    select(onexit_seq_traces, package, type, tag, onexit=n_complete),
    by=c("package", "type", "tag")
  ) %>% 
  full_join(
    select(ondotexit_seq_traces, package, type, tag, ondotexit=n_complete),
    by=c("package", "type", "tag")
  ) %>%
  select(package, type, tag, n_entry, onexit, ondotexit)

n_diffs_calls <- diffs_calls %>%
  group_by(package) %>%
  summarise(
    n_entry=sum(n_entry),
    onexit=sum(onexit),
    ondotexit=sum(ondotexit)
  ) %>%
  mutate(
    r1=ifelse(n_entry > 0, 1-onexit/n_entry, 0),
    r2=ifelse(n_entry > 0, 1-ondotexit/n_entry, 0),
    d=ifelse(r1 > 0, r2/r1, 0)
  ) %>%
  select(package, r1, r2, d)

n_diffs_calls %>%
  filter(d != 0) %>%
  ggplot(
    aes(
      x=factor(package, levels=n_diffs_calls$package[order(n_diffs_calls$d)]), 
      y=d
    )
  ) +
  geom_col() +
  scale_y_continuous(labels=scales::percent_format()) +
  coord_flip() +
  labs(
    title="on.exit vs onexit - number of calls on.exit records over onexit",
    subtitle="Which decorator is better?",
    x="Package",
    y="Ratio of captured calls"
  )
```

```{r}
p0 = ggplot(n_diffs_calls, aes(y=d)) + geom_violin(aes(x = "on.exit / onexit"))

# compute lower and upper whiskers
ylim1 = boxplot.stats(n_diffs_calls$d)$stats[c(1, 5)]

# scale y limits based on ylim1
p0 + coord_cartesian(ylim = ylim1*1.05) +   labs(
    title="on.exit vs onexit overview without outliers",
    subtitle="Which decorator is better?",
    y="Ratio of captured calls"
  )
```

### Test size

```{r load test size}
test_sizes <- load_file_from_packages(
  file.path("trace-on.exit--set", "output", "all"), 
  from=left_join(filter(s_traces, tests > 0), all_packages, by="package"), 
  function(package, fname) {
    files <- list.files(fname, pattern="test-.*\\.R$", full.names=TRUE, recursive=TRUE)
    data_frame(package=package, file=files, size=file.size(files))
  }
)
```

```{r test size, fig.height=13}
test_sizes %>%
  ggplot(aes(x="size", y=size)) +
  geom_violin() +
  scale_y_log10(labels=function(x) {
    if (length(x) == 0) return(character())
    sapply(x, format_size, USE.NAMES=FALSE)
  }) +
  labs(
    title="Distribution of test size",
    x="Size (log)"
  )
```

#### TOP 100

```{r}
test_sizes %>% 
  top_n(100, size) %>% 
  arrange(desc(size)) %>%
  mutate(size=format_size(size)) %>% 
  datatable()
```

## Test runs

### Inconsistent data

There is one expectation per test. Running the code might generate some warnings. 
However, the number of assertions (`nb-waring`) should be 1. 
If it is not, there is a problem.

```{r}
run_tests %>% filter((nb - warning) > 1) %>% count(package) %>% datatable()
```


# Coverage

```{r coverage data}
library(covr)

percent_coverage_checked <- function(covr_df) {
  try(percent_coverage(covr_df), silent=TRUE)
}

load_coverage <- function(type) {
  coverage <- pblapply(file.path(packages_with_covr$path, "coverage", "output", type, "covr.RDS"), readRDS, cl=4)
  p_coverage <- pblapply(coverage, percent_coverage_checked, cl=4)
  lapply(p_coverage, function(x) if (is.numeric(x)) x else NA)
}

packages_with_covr <- filter(all_packages, coverage) %>% select(package, path)
dependencies <- tools::package_dependencies(packages_with_covr$package, which = c("Depends", "Imports"), reverse = TRUE)

all_coverage <- load_coverage("all")
tests_coverage <- load_coverage("tests")

s_coverage <- mutate(
  packages_with_covr, 
  all_coverage=unlist(all_coverage), 
  tests_coverage=unlist(tests_coverage),
  diff_coverage=all_coverage-tests_covrage,
  dependencies=sapply(dependencies, length)
)

s_coverage <- s_coverage[complete.cases(s_coverage), ]
```

```{r coverage result}
ggplot(s_coverage, aes(x=dependencies, y=all_coverage, label=package)) + 
  geom_point() + 
  geom_text(size=2, vjust = 0, nudge_y = 0.5) + 
  scale_x_log10()
```

```{r}
filter(all_packages, !coverage, run_package) %>% datatable()
```

```{r}
read_file_checked <- function(path) {
  if (file.exists(path)) {
    str_c(read_file(path), collapse="\n")
  } else {
    NA
  }
}

covr_err <- 
  filter(all_packages, !coverage, run_package) %>% 
  mutate(stderr=pbsapply(path, function(x) read_file_checked(file.path(x, "coverage", "1", "all", "stderr")), USE.NAMES=FALSE)) %>%
  select(package, stderr)
```


# Setup

git commit:

```{sh}
git rev-parse HEAD
```

all packages:

```{r}
all_packages %>% datatable()
```